{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('ASR_1.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I COULD HAVE BECOME a mass murderer after I hacked my governor module, but then I realized I could access the combined feed of entertainment channels carried on the company satellites. It had been well over 35,000 hours or so since then, with still not much murdering, but probably, I donâ€™t know, a little under 35,000 hours of movies, serials, books, plays, and music consumed. As a heartless killing machine, I was a terrible failure.\\n\\nI was also still doing my job, on a new contract, and hoping Dr. Volescu and Dr. Bharadwaj finished their survey soon so we could get back to the habitat and I could watch episode 397 of Rise and Fall of Sanctuary Moon.\\n\\nI admit I was distracted. It was a boring contract so far and I was thinking about backburnering the status alert channel and trying to access music on the entertainment feed without HubSystem logging the extra activity. It was trickier to do it in the field than it was in the habitat.\\n\\nThis assessment zone was a barren stretch of coastal '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'\\s+', ' ', text)\n",
    "text = re.sub(r'[^A-Za-z0-9\\s]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i could have become a mass murderer after i hacked my governor module but then i realized i could ac'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= text.lower()\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'could', 'have', 'become', 'a']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = word_tokenize(text)\n",
    "tokenized_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['could',\n",
       " 'become',\n",
       " 'mass',\n",
       " 'murderer',\n",
       " 'hacked',\n",
       " 'governor',\n",
       " 'module',\n",
       " 'realized',\n",
       " 'could',\n",
       " 'access']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = [token for token in tokenized_text if token not in stop_words]\n",
    "filtered_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['could',\n",
       " 'becom',\n",
       " 'mass',\n",
       " 'murder',\n",
       " 'hack',\n",
       " 'governor',\n",
       " 'modul',\n",
       " 'realiz',\n",
       " 'could',\n",
       " 'access']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed_text = [stemmer.stem(token) for token in filtered_text]\n",
    "\n",
    "stemmed_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "lemmatized_text = [nlp(token) for token in filtered_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[could,\n",
       " become,\n",
       " mass,\n",
       " murderer,\n",
       " hacked,\n",
       " governor,\n",
       " module,\n",
       " realized,\n",
       " could,\n",
       " access]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "davenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
