{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series wise Topic Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to replace the chapter names with the correct chapter order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function in test_eda.ipynb so need to put this in one place in the the scripts\n",
    "def chapter_order(filename):\n",
    "\n",
    "    book_number = filename.split('_')[0]\n",
    "    chapter_number = filename.split('_')[2].zfill(2)\n",
    "    new_name = book_number + '.' + chapter_number\n",
    "    \n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Chapter name and text dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all chapters to one list of chapter text\n",
    "# one element of the list = one chapter\n",
    "# Just like text_sentiment_analysis.ipynb\n",
    "\n",
    "mb_dir = '../2_Text_Preprocessing/TMBD_Chapters_lemma'\n",
    "\n",
    "mb_chapter_texts = {}\n",
    "\n",
    "for filename in os.listdir(mb_dir):\n",
    "    filepath =  os.path.join(mb_dir, filename)\n",
    "    with open(filepath, 'r', encoding='utf-8') as chapter_file:\n",
    "        chapter_text = chapter_file.read()\n",
    "        mb_chapter_texts[chapter_order(filename)] = chapter_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all chapters to one list of chapter text\n",
    "# one element of the list = one chapter\n",
    "# same as test_sentiment_analysis.ipynb\n",
    "\n",
    "ir_dir = '../2_Text_Preprocessing/IR_Chapters_lemma'\n",
    "\n",
    "ir_chapter_texts = {}\n",
    "\n",
    "for filename in os.listdir(ir_dir):\n",
    "    filepath =  os.path.join(ir_dir, filename)\n",
    "    with open(filepath, 'r', encoding='utf-8') as chapter_file:\n",
    "        chapter_text = chapter_file.read()\n",
    "        ir_chapter_texts[chapter_order(filename)] = chapter_text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have both dictionaries with chapter names as keys and chapter text as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_corpus_dict = corpora.Dictionary([values for key, values in mb_chapter_texts.items()])\n",
    "mb_corpus = [mb_corpus_dict.doc2bow(values) for key, values in mb_chapter_texts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_corpus_dict = corpora.Dictionary([values for key, values in ir_chapter_texts.items()])\n",
    "ir_corpus = [ir_corpus_dict.doc2bow(values) for key, values in ir_chapter_texts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.018*\"said\" + 0.012*\"art\" + 0.007*\"know\" + 0.007*\"humans\" + 0.007*\"like\"')\n",
      "(1, '0.009*\"said\" + 0.008*\"feed\" + 0.008*\"humans\" + 0.008*\"one\" + 0.007*\"didnt\"')\n",
      "(2, '0.013*\"said\" + 0.007*\"could\" + 0.007*\"humans\" + 0.007*\"would\" + 0.007*\"feed\"')\n",
      "(3, '0.007*\"said\" + 0.006*\"art\" + 0.006*\"humans\" + 0.006*\"overse\" + 0.005*\"could\"')\n",
      "(4, '0.009*\"said\" + 0.007*\"station\" + 0.007*\"like\" + 0.007*\"indah\" + 0.007*\"humans\"')\n"
     ]
    }
   ],
   "source": [
    "mb_lda_model = LdaModel(corpus=mb_corpus, id2word=mb_corpus_dict, num_topics=5, random_state=42, passes=15)\n",
    "\n",
    "mb_topics = mb_lda_model.print_topics(num_words=5)\n",
    "\n",
    "for topic in mb_topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.018*\"station\" + 0.012*\"said\" + 0.012*\"seivarden\" + 0.010*\"sword\" + 0.008*\"would\"')\n",
      "(1, '0.017*\"lieutenant\" + 0.013*\"said\" + 0.011*\"would\" + 0.011*\"one\" + 0.009*\"awn\"')\n",
      "(2, '0.016*\"said\" + 0.010*\"captain\" + 0.009*\"would\" + 0.008*\"one\" + 0.007*\"seivarden\"')\n",
      "(3, '0.010*\"said\" + 0.009*\"would\" + 0.009*\"one\" + 0.006*\"could\" + 0.005*\"lieutenant\"')\n",
      "(4, '0.007*\"kalr\" + 0.006*\"ship\" + 0.006*\"would\" + 0.005*\"medic\" + 0.005*\"one\"')\n"
     ]
    }
   ],
   "source": [
    "ir_lda_model = LdaModel(corpus=ir_corpus, id2word=ir_corpus_dict, num_topics=5, random_state=42, passes=15)\n",
    "\n",
    "ir_topics = ir_lda_model.print_topics(num_words=5)\n",
    "\n",
    "for topic in ir_topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series wise TF-IDF for Theme Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn. feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "mb_tfidf_matrix = mb_vectorizer.fit_transform([\" \".join(values) for key, values in mb_chapter_texts.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said\n",
      "humans\n",
      "didnt\n",
      "feed\n",
      "art\n",
      "like\n",
      "know\n",
      "ratthi\n",
      "mensah\n",
      "human\n"
     ]
    }
   ],
   "source": [
    "mb_feature_names = mb_vectorizer.get_feature_names_out()\n",
    "\n",
    "mb_tfidf_sums = mb_tfidf_matrix.sum(axis=0)\n",
    "mb_sorted_indices = mb_tfidf_sums.argsort()[0, ::-1]\n",
    "\n",
    "mb_top_words = [mb_feature_names[i] for i in mb_sorted_indices[:10]]\n",
    "for word in mb_top_words[0][0][:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "ir_tfidf_matrix = ir_vectorizer.fit_transform([\" \".join(values) for key, values in ir_chapter_texts.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said\n",
      "lieutenant\n",
      "seivarden\n",
      "captain\n",
      "station\n",
      "tisarwat\n",
      "didnt\n",
      "fleet\n",
      "ship\n",
      "know\n"
     ]
    }
   ],
   "source": [
    "ir_feature_names = ir_vectorizer.get_feature_names_out()\n",
    "\n",
    "ir_tfidf_sums = ir_tfidf_matrix.sum(axis=0)\n",
    "ir_sorted_indices = ir_tfidf_sums.argsort()[0, ::-1]\n",
    "\n",
    "ir_top_words = [ir_feature_names[i] for i in ir_sorted_indices[:10]]\n",
    "for word in ir_top_words[0][0][:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So not much difference from the word frequencies in test_eda.ipynb\n",
    "\n",
    "- both texts have \"said\" as a theme which makes sense for books made of a lot of dialogue or any kind of written fiction.\n",
    "\n",
    "- in MB ratthi is a topic higher than mensah, which is interesting. ART is also higher up and humans still are a central theme. despite this series being about machine intelligences, the focus is entirely human. interesting.\n",
    "\n",
    "- in IR series, the titles are still as important and what i take to be main characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next thing: chapter wise theme and topic detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
